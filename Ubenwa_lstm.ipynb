{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "zEnjws4AA-k0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers\n",
        "! pip install datasets\n",
        "! pip install Sentencepiece\n",
        "! pip install torchmetrics\n",
        "! pip install evaluate\n",
        "! pip install audiomentations\n",
        "! pip install huggingface_hub"
      ],
      "metadata": {
        "id": "dk9ZveuUnzIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a395997-2133-4430-d6ca-cde97eb5e0ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.7.1)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Sentencepiece in /usr/local/lib/python3.8/dist-packages (0.1.97)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.8/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.8/dist-packages (0.3.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.7.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.23.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2022.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from evaluate) (21.3)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.3.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from evaluate) (4.64.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.11.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->evaluate) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: audiomentations in /usr/local/lib/python3.8/dist-packages (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.8/dist-packages (from audiomentations) (1.21.6)\n",
            "Requirement already satisfied: scipy<2,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from audiomentations) (1.7.3)\n",
            "Requirement already satisfied: librosa<0.10.0,>0.7.2 in /usr/local/lib/python3.8/dist-packages (from audiomentations) (0.8.1)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.8/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (0.56.4)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (1.6.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (1.0.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (3.0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (21.3)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (0.4.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.8/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (0.11.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa<0.10.0,>0.7.2->audiomentations) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa<0.10.0,>0.7.2->audiomentations) (0.39.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa<0.10.0,>0.7.2->audiomentations) (4.13.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->librosa<0.10.0,>0.7.2->audiomentations) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (1.4.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa<0.10.0,>0.7.2->audiomentations) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.10.2->librosa<0.10.0,>0.7.2->audiomentations) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa<0.10.0,>0.7.2->audiomentations) (2.21)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.43.0->librosa<0.10.0,>0.7.2->audiomentations) (3.11.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.8/dist-packages (0.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface_hub) (3.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from huggingface_hub) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from huggingface_hub) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface_hub) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface_hub) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface_hub) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.9->huggingface_hub) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface_hub) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface_hub) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface_hub) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface_hub) (2022.9.24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdCdv-FQBfTi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cacba5b-c3ca-4687-bef4-eb3fd53f1807"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git version"
      ],
      "metadata": {
        "id": "jRX_bIKoeiFD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1102af9-d386-4f60-c18f-ca7dc5c3c000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "git version 2.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email “pamelyking@gmail.com”\n",
        "!git config --global user.name “pamely”"
      ],
      "metadata": {
        "id": "3N3It_MJekKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://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@github.com/pamely/idl-project.git "
      ],
      "metadata": {
        "id": "gN5ftqVWfbm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6c2bb2e-5015-40aa-e587-05adbf3fd0fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: /content/drive/MyDrive/F22/IDL-Project/idl-project/data/BabyChillantoDB: Is a directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "61H7VpYT-v1L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ace8f9f-cc39-4027-cb01-223787e0304a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint  idl-project  Ubenwa  Ubenwa-Pam  Ubenwa-Pam-lstm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd idl-project/"
      ],
      "metadata": {
        "id": "AhZ2fZtW-26G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.nn import *\n",
        "import torch.optim as optim\n",
        "import torchaudio\n",
        "import os, gc\n",
        "# from torchmetrics.classification import BinaryHingeLoss\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau, MultiStepLR\n",
        "\n",
        "# Transformer-Based Models:\n",
        "import librosa\n",
        "#Importing Pytorch\n",
        "import torch\n",
        "#Importing Wav2Vec\n",
        "\n",
        "# quality-of-life packages\n",
        "from tqdm import tqdm # so that data-loading process can be visualized\n",
        "from torchsummary import summary # summary of the model\n",
        "\n",
        "import random\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device: \", device)"
      ],
      "metadata": {
        "id": "bBCv6JMOA9GG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e6af1f7-ab89-4c10-d522-ffc52b6d7f74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config:"
      ],
      "metadata": {
        "id": "SPmaSyIfVtAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"epochs\": 50,\n",
        "    \"batch-size\": 50,\n",
        "    \"lr\": 0.01,\n",
        "    \"momentum\": 0.9,\n",
        "    \"weight-decay\": 0,\n",
        "    \"scheduler-step-size\": [15],\n",
        "    \"scheduler-gamma\": 0.1,\n",
        "    \"seed\": 11785,\n",
        "    \"label-smoothing\": 0\n",
        "}"
      ],
      "metadata": {
        "id": "JPal8gexVsX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data-Preprocessing"
      ],
      "metadata": {
        "id": "Og0T8e_AAQBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyPipeline(torch.nn.Module):\n",
        "    def __init__(self, orig_freq, new_freq=8000):\n",
        "\n",
        "        super().__init__()\n",
        "        self.orig_freq = orig_freq\n",
        "        self.new_freq = new_freq\n",
        "\n",
        "        # win_length, hop_length based on paper and intuition from these posts:\n",
        "        # https://groups.google.com/g/librosa/c/xeodGZVDE1s\n",
        "        # melkwargs={\"win_length\": 240, \"hop_length\": 80, \"f_min\": 20, \"f_max\": 4000, \"n_mels\": 40}\n",
        "        self.mfcc = torchaudio.transforms.MFCC(sample_rate=new_freq)\n",
        "        self.resample = torchaudio.transforms.Resample(new_freq=new_freq, orig_freq=orig_freq)\n",
        "\n",
        "\n",
        "    def forward(self, waveform : torch.Tensor) -> torch.Tensor:\n",
        "        if (waveform.shape[1] != self.orig_freq):\n",
        "          transform_fn_tmp = torchaudio.transforms.Resample(new_freq=self.new_freq, orig_freq=waveform.shape[1])\n",
        "          resampled = transform_fn_tmp(waveform)\n",
        "        else:\n",
        "          resampled = self.resample(waveform)\n",
        "\n",
        "        resampled_audio_list = np.array(resampled)[0]\n",
        "        mfcc = self.mfcc(resampled)\n",
        "        assert(len(np.array(resampled)[0]) != 1)\n",
        "        return resampled_audio_list, mfcc\n",
        "\n",
        "\n",
        "#TODO: This does not look like it is returning random data samples\n",
        "class BabyChillanto(torch.utils.data.Dataset):\n",
        "    def __init__(self, control_path, disease_path, partition=\"train\", audio_input=False):\n",
        "        self.mfcc, self.label = [], []\n",
        "        self.audio_files = [] # for the transformer model\n",
        "        control_names = os.listdir(control_path)\n",
        "        disease_names = os.listdir(disease_path)\n",
        "\n",
        "        train_split_control = int(len(control_names) * 0.6) # 60-20-20 split from paper\n",
        "        train_split_disease = int(len(disease_names) * 0.6)\n",
        "\n",
        "        val_split_control = int(len(control_names))\n",
        "        val_split_disease = int(len(control_names))\n",
        "\n",
        "        if partition == \"train\":\n",
        "            control_names = control_names[:train_split_control]\n",
        "            disease_names = disease_names[:train_split_disease]\n",
        "\n",
        "        elif (partition == \"val\" or partition == \"test\"):\n",
        "            control_names = control_names[train_split_control:val_split_control]\n",
        "            disease_names = disease_names[train_split_disease:val_split_disease]\n",
        "\n",
        "        # elif partition == \"test\":\n",
        "        #     control_names = control_names[val_split_control:]\n",
        "        #     disease_names = disease_names[val_split_disease:]\n",
        "\n",
        "        else:\n",
        "            raise NameError(\"Unknown partition\")\n",
        "\n",
        "        pipeline = MyPipeline(orig_freq=24000, new_freq=16000) # sampling for transformer defaults to 16000 sampling rate\n",
        "\n",
        "        # Note: 1 = Control, 0 = Asphyxia\n",
        "        print(\"Loading Control\")\n",
        "        for v in tqdm(control_names):\n",
        "            data_path = os.path.join(control_path, v)\n",
        "            waveform, sample_rate = torchaudio.load(data_path)\n",
        "\n",
        "            # print(waveform.shape)\n",
        "            if (np.all(np.array(waveform) - 0 <= 10e-6)): # remove waveforms of all zeros\n",
        "              continue\n",
        "            audio_file, mfcc = pipeline(waveform)\n",
        "            # mfcc -= (np.mean(mfcc, axis=0) + 1e-8)\n",
        "\n",
        "            # if (np.all(mfcc == 0)):\n",
        "            #   continue # remove mfccs of all zeros\n",
        "            self.mfcc.append(mfcc)\n",
        "            self.audio_files.append(audio_file)\n",
        "            # l = torch.zeros(2)\n",
        "            # l[0] = 1\n",
        "            self.label.append(1)\n",
        "\n",
        "        print(\"Loading Asphyxia\")\n",
        "        for v in tqdm(disease_names):\n",
        "            data_path = os.path.join(disease_path, v)\n",
        "            waveform, sample_rate = torchaudio.load(data_path)\n",
        "\n",
        "            if (np.all(np.array(waveform) - 0 <= 10e-6)): # remove waveforms of all zeros\n",
        "              continue\n",
        "            audio_file, mfcc = pipeline(waveform)\n",
        "            # mfcc -= (np.mean(mfcc, axis=0) + 1e-8)\n",
        "\n",
        "            # if (np.all(mfcc == 0)):\n",
        "            #   continue # remove mfccs of all zeros\n",
        "            self.mfcc.append(mfcc)\n",
        "            self.audio_files.append(audio_file)\n",
        "            # l = torch.zeros(2)\n",
        "            # l[1] = 1\n",
        "            self.label.append(0)\n",
        "        assert len(self.mfcc) == len(self.label)\n",
        "\n",
        "\n",
        "        # Suffle the data\n",
        "        # both = list(zip(self.mfcc, self.label))\n",
        "        # random.shuffle(both)\n",
        "        # self.mfcc, self.label = zip(*both)\n",
        "\n",
        "        # Padding the MFCCs to be the same size:\n",
        "        # Find maximum width of mfcc:\n",
        "        shapes_width = [mfcc.shape[2] for mfcc in self.mfcc]\n",
        "        max_width = max(shapes_width)\n",
        "        for i in range(len(self.mfcc)):\n",
        "          if (max_width - self.mfcc[i].shape[2] == 0):\n",
        "            continue\n",
        "          padding_amount = nn.ConstantPad1d((0, max_width - self.mfcc[i].shape[2]), 0)\n",
        "          self.mfcc[i] = padding_amount(self.mfcc[i])\n",
        "\n",
        "        if (audio_input):\n",
        "          self.length = len(self.audio_files)\n",
        "          self.inputs = self.audio_files\n",
        "        else:\n",
        "          self.length = len(self.mfcc)\n",
        "          self.inputs = self.mfcc\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "\n",
        "        input = self.inputs[ind].squeeze(1)\n",
        "        label = self.label[ind]\n",
        "\n",
        "\n",
        "        return input, label\n",
        "\n",
        "    # def collate_fn(self, batch):\n",
        "    #   data = [item[0] for item in batch]\n",
        "    #   target = [item[1] for item in batch]\n",
        "    #   target = torch.LongTensor(target)\n",
        "    #   return [data, target]"
      ],
      "metadata": {
        "id": "Sie2R0Yi2nf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Datasets + Check for Transformer Parameters:"
      ],
      "metadata": {
        "id": "McpURl8W2QvM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Datasets"
      ],
      "metadata": {
        "id": "u9A6prQcndfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (I changed the filepath s.t. it's easier to just use the dataset locally)\n",
        "# asphyxia_filepath = \"/content/drive/MyDrive/F22/IDL-Project/idl-project/Bootstrapped/tanh/1s_asphyxia\"\n",
        "# normal_filepath = \"/content/drive/MyDrive/F22/IDL-Project/idl-project/Bootstrapped/tanh/1s_normal\"\n",
        "\n",
        "# torch.manual_seed(config[\"seed\"])\n",
        "\n",
        "\n",
        "# train_data = BabyChillanto(normal_filepath, asphyxia_filepath, partition=\"train\")\n",
        "# val_data = BabyChillanto(normal_filepath, asphyxia_filepath, partition=\"val\")\n",
        "\n",
        "# train_data_audio = BabyChillanto(normal_filepath, asphyxia_filepath, partition=\"train\", audio_input = True)\n",
        "# val_data_audio = BabyChillanto(normal_filepath, asphyxia_filepath, partition=\"val\", audio_input = True)\n",
        "\n",
        "# # potentially todo: increase the number of files processed\n",
        "# train_loader = torch.utils.data.DataLoader(train_data, num_workers= 1,\n",
        "#                                            batch_size= config[\"batch-size\"], pin_memory= True,\n",
        "#                                            shuffle= True)\n",
        "\n",
        "\n",
        "# val_loader = torch.utils.data.DataLoader(val_data, num_workers= 1,\n",
        "#                                          batch_size= config[\"batch-size\"], pin_memory= True,\n",
        "#                                          shuffle= False)\n",
        "\n",
        "# train_loader_audio = torch.utils.data.DataLoader(train_data_audio, num_workers= 1,\n",
        "#                                            batch_size= config[\"batch-size\"], pin_memory= True,\n",
        "#                                            shuffle= True)\n",
        "\n",
        "\n",
        "# val_loader_audio = torch.utils.data.DataLoader(val_data_audio, num_workers= 1,\n",
        "#                                          batch_size= config[\"batch-size\"], pin_memory= True,\n",
        "#                                          shuffle= False)\n",
        "\n",
        "\n",
        "asphyxia_filepath = \"/content/drive/MyDrive/F22/IDL-Project/idl-project/data/BabyChillantoDB/reverb/1s_asphyxia\"\n",
        "normal_filepath = \"/content/drive/MyDrive/F22/IDL-Project/idl-project/data/BabyChillantoDB/reverb/1s_normal\"\n",
        "\n",
        "torch.manual_seed(config[\"seed\"])\n",
        "\n",
        "train_data = BabyChillanto(normal_filepath, asphyxia_filepath, partition=\"train\")\n",
        "val_data = BabyChillanto(normal_filepath, asphyxia_filepath, partition=\"val\")\n",
        "\n",
        "train_data_audio = BabyChillanto(normal_filepath, asphyxia_filepath, partition=\"train\", audio_input = True)\n",
        "val_data_audio = BabyChillanto(normal_filepath, asphyxia_filepath, partition=\"val\", audio_input = True)\n",
        "\n",
        "# potentially todo: increase the number of files processed\n",
        "train_loader = torch.utils.data.DataLoader(train_data, num_workers= 1,\n",
        "                                           batch_size= config[\"batch-size\"], pin_memory= True,\n",
        "                                           shuffle= True)\n",
        "\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_data, num_workers= 1,\n",
        "                                         batch_size= config[\"batch-size\"], pin_memory= True,\n",
        "                                         shuffle= False)\n",
        "\n",
        "train_loader_audio = torch.utils.data.DataLoader(train_data_audio, num_workers= 1,\n",
        "                                           batch_size= config[\"batch-size\"], pin_memory= True,\n",
        "                                           shuffle= True)\n",
        "\n",
        "\n",
        "val_loader_audio = torch.utils.data.DataLoader(val_data_audio, num_workers= 1,\n",
        "                                         batch_size= config[\"batch-size\"], pin_memory= True,\n",
        "                                         shuffle= False)\n"
      ],
      "metadata": {
        "id": "3CR4Dp6R2QUo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42559a10-4294-486c-d35c-9ad24e572af0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchaudio/functional/functional.py:571: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Control\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 608/608 [00:09<00:00, 65.77it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Asphyxia\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 408/408 [01:15<00:00,  5.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Control\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 406/406 [00:01<00:00, 272.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Asphyxia\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 272/272 [00:50<00:00,  5.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Control\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 608/608 [00:02<00:00, 245.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Asphyxia\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 408/408 [00:02<00:00, 176.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Control\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 406/406 [00:01<00:00, 270.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Asphyxia\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 272/272 [00:01<00:00, 170.05it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LSTM"
      ],
      "metadata": {
        "id": "Z-RJpd3pn9v6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for data in train_loader:\n",
        "    x, label = data\n",
        "    print(x.shape, label.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "6EuysWSh8IHW",
        "outputId": "06272c47-1ab2-47c8-c327-8fd13b56387b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ae21a2cde523>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1333\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1357\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\", line 61, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py\", line 143, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py\", line 143, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py\", line 120, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py\", line 162, in collate_tensor_fn\n    out = elem.new(storage).resize_(len(batch), *list(elem.size()))\nRuntimeError: Trying to resize storage that is not resizable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUT_SIZE = 2 \n",
        "\n",
        "class LSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size = 81 , output_channel = 256, n_layers=3, hidden_size=256, num_classes = 2):\n",
        "\n",
        "        super(LSTM, self).__init__()\n",
        "\n",
        "        # Adding some sort of embedding layer or feature extractor might help performance.\n",
        "        # self.embedding1 = nn.Conv1d(input_size, 128, 5, padding='same')\n",
        "        # self.embedding2 = nn.Conv1d(128, output_channel, 5, padding='same')\n",
        "\n",
        "        self.embedding = nn.Sequential(\n",
        "           nn.Conv1d(input_size, 128, 5, padding='same'),\n",
        "           nn.BatchNorm1d(128),\n",
        "           nn.GELU(),\n",
        "           nn.Dropout(0.0),\n",
        "\n",
        "           nn.Conv1d(128, 256, 5, padding='same'),\n",
        "           nn.BatchNorm1d(256),\n",
        "           nn.GELU(),\n",
        "           nn.Dropout(0.2),\n",
        "\n",
        "           nn.Conv1d(256, 512, 5, padding='same'),\n",
        "           nn.BatchNorm1d(512),\n",
        "           nn.GELU(),\n",
        "           nn.Dropout(0.5)\n",
        "          )\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # TODO : look up the documentation. You might need to pass some additional parameters.\n",
        "        self.lstm = nn.LSTM(input_size = output_channel, \n",
        "                            hidden_size = hidden_size,\n",
        "                            num_layers = n_layers, \n",
        "                            batch_first=True, \n",
        "                            bidirectional=True,\n",
        "                            dropout=0.2\n",
        "                            )\n",
        "        self.classification = nn.Sequential( \n",
        "            nn.Linear(20480, 2048), \n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            # adding this layer for the Baby \n",
        "            \n",
        "            nn.Linear(2048, num_classes)\n",
        "        )\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "      \n",
        "        x = x.permute(0,2,1)\n",
        "\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        x = x.permute(0,2,1)\n",
        "\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "      \n",
        "        out = self.classification(lstm_out.reshape((x.size(0), -1)))\n",
        "\n",
        "        return  out\n"
      ],
      "metadata": {
        "id": "NcvqTgyRnYh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "model = LSTM(output_channel = 512, n_layers = 3, hidden_size = 256).to(device) "
      ],
      "metadata": {
        "id": "BriaxahUp8Y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = model(x.squeeze(1).to(device))\n",
        "\n",
        "out.size()"
      ],
      "metadata": {
        "id": "FPei1p_9OWNp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "2eec5ea7-477c-4694-ea96-d75ddfd552a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-ba9f6909da26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_config = {\n",
        "    \"beam_width\" : 2,\n",
        "    \"lr\" : 1e-3,\n",
        "    \"epochs\" : 30\n",
        "    }"
      ],
      "metadata": {
        "id": "YvYeQIstHpj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss() #Defining Loss function \n",
        "# criterion = torch.nn.BCELoss() #Defining Loss function \n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=train_config['lr'], weight_decay=1e-5) #Defining Optimizer\n",
        "\n",
        "# Recommended : Define Scheduler for Learning Rate, including but not limited to StepLR, MultiStepLR, CosineAnnealingLR, ReduceLROnPlateau, etc. \n",
        "# You can refer to Pytorch documentation for more information on how to use them.\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=2)\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ],
      "metadata": {
        "id": "K_6IKgsskXDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, model, optimizer, criterion, scaler):\n",
        "    \n",
        "\n",
        "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
        "    total_loss = 0\n",
        "    num_correct = 0\n",
        "\n",
        "    model.train()\n",
        "    \n",
        "    for i, (mfccs, labels) in enumerate(train_loader):\n",
        "        \n",
        "        optimizer.zero_grad() # Zero gradients\n",
        "       \n",
        "        mfccs, labels = mfccs.to(device), labels.to(device)\n",
        "            \n",
        "        outputs = model(mfccs.squeeze(1))\n",
        " \n",
        "        loss = criterion(outputs, labels) # for HingeLoss, you use the predictions\n",
        "\n",
        "        preds = torch.argmax(outputs, axis=1)\n",
        "\n",
        "        num_correct += int((preds == labels).sum())\n",
        "\n",
        "        total_loss += float(loss.item())\n",
        "\n",
        "        batch_bar.set_postfix(\n",
        "            \n",
        "            acc=\"{:.04f}%\".format(100 * num_correct / (config['batch-size']*(i + 1))),\n",
        "\n",
        "            loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "           \n",
        "            num_correct=num_correct,\n",
        "\n",
        "            lr=\"{:.04f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
        "        \n",
        "        loss.backward(retain_graph = True)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # TODO? Depending on your choice of scheduler,\n",
        "        # You may want to call some schdulers inside the train function. What are these?\n",
        "      \n",
        "        batch_bar.update() # Update tqdm bar\n",
        "\n",
        "    batch_bar.close() # You need this to close the tqdm bar\n",
        "\n",
        "    acc = 100 * num_correct / (config['batch-size'] * len(train_loader))\n",
        "    total_loss = float(total_loss / len(train_loader))\n",
        "\n",
        "    return acc, total_loss #, total_fine_tuning_loss"
      ],
      "metadata": {
        "id": "PLXWNNRZyafX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(train_loader, model, optimizer, criterion, scaler):\n",
        "    \n",
        "\n",
        "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
        "    total_loss = 0\n",
        "    num_correct = 0\n",
        "\n",
        "    model.train()\n",
        "    for i, (mfccs, labels) in enumerate(train_loader):\n",
        "        \n",
        "        optimizer.zero_grad() # Zero gradients\n",
        "        # optimizer_center_loss.zero_grad()\n",
        "\n",
        "        mfccs, labels = mfccs.to(device), labels.to(device)\n",
        "        # print(labels.shape)\n",
        "        \n",
        "        # with torch.cuda.amp.autocast(): # This implements mixed precision. Thats it! \n",
        "        # no need for mixed precision\n",
        "            # mfccs = torch.Tensor.cpu(mfccs)\n",
        "        print(mfccs.shape)\n",
        "            \n",
        "        outputs = model(mfccs.squeeze(1))\n",
        "        # print(type(outputs))\n",
        "        # print(outputs)\n",
        "\n",
        "        # softmax_fn = torch.nn.Softmax(dim=1)\n",
        "        # probs_outputs = softmax_fn(outputs)\n",
        "\n",
        "        # max_outputs = np.zeros(len(labels))\n",
        "        # print(preds)\n",
        "        # print(labels)\n",
        "        # assert(False)\n",
        "\n",
        "        # for i in range(len(max_outputs)):\n",
        "        #   if (preds[i] == 0):\n",
        "        #     max_outputs[i] = 1 - probs_outputs[i][0]\n",
        "        #     assert(max_outputs[i] <= 0.5)\n",
        "        #   else: # preds[i] == 1\n",
        "        #     max_outputs[i] = probs_outputs[i][1]\n",
        "\n",
        "\n",
        "        loss = criterion(outputs, labels) # for HingeLoss, you use the predictions\n",
        "\n",
        "        # Update no. of correct predictions & loss as we iterate\n",
        "        # print(outputs)\n",
        "        # print(torch.argmax(outputs, axis=1))\n",
        "        # print(labels)\n",
        "        preds = torch.argmax(outputs, axis=1)\n",
        "        num_correct += int((preds == labels).sum())\n",
        "        total_loss += float(loss.item())\n",
        "        # total_fine_tuning_loss += float(loss1.item())\n",
        "\n",
        "        # tqdm lets you add some details so you can monitor training as you train.\n",
        "        batch_bar.set_postfix(\n",
        "            acc=\"{:.04f}%\".format(100 * num_correct / (config['batch-size']*(i + 1))),\n",
        "            loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "            #fine_tuning_loss = \"{:.04f}\".format(float(total_fine_tuning_loss / (i + 1))),\n",
        "            num_correct=num_correct,\n",
        "            lr=\"{:.04f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
        "        # loss.backward(retain_graph = True)\n",
        "        # scaler.scale(loss).backward(retain_graph=True) # You have to pass retain_graph=True here, so that the scaler will remember this backward call\n",
        "        # scaler.scale(loss1).backward()\n",
        "\n",
        "        # for parameter in fine_tuning_criterion.parameters():\n",
        "        #     parameter.grad.data *= (1.0 / loss_weight)\n",
        "        optimizer.step()\n",
        "        # scaler.step(optimizer)  \n",
        "        # scaler.step(optimizer_center_loss)\n",
        "        # scaler.update() \n",
        "\n",
        "        # TODO? Depending on your choice of scheduler,\n",
        "        # You may want to call some schdulers inside the train function. What are these?\n",
        "      \n",
        "        batch_bar.update() # Update tqdm bar\n",
        "\n",
        "    batch_bar.close() # You need this to close the tqdm bar\n",
        "\n",
        "    acc = 100 * num_correct / (config['batch-size'] * len(train_loader))\n",
        "    total_loss = float(total_loss / len(train_loader))\n",
        "\n",
        "    return acc, total_loss #, total_fine_tuning_loss"
      ],
      "metadata": {
        "id": "tEyicGBSTeFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "ref_acc = 0\n",
        "\n",
        "#TODO: Please complete the training loop\n",
        "\n",
        "\n",
        "for epoch in range(train_config[\"epochs\"]):\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  print(\"\\nEpoch {}/{}\".format(epoch+1, train_config[\"epochs\"]))\n",
        "\n",
        "  train_loss = train(train_loader, model, optimizer, criterion, scaler)\n",
        "\n",
        "  accuracy, val_loss = eval(train_loader, model, optimizer, criterion, scaler)\n",
        "\n",
        "  scheduler.step(val_loss)\n",
        "\n",
        "\n",
        "  lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
        "\n",
        "  print(\"\\tTrain Loss: {:.4f}\".format(train_loss[1]))\n",
        "\n",
        "  print(\"\\tValidation Loss: {:.4f}\".format(val_loss))\n",
        "\n",
        "  print(\"\\tValidation accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "  if accuracy >= ref_acc:\n",
        "     torch.save({'model_state_dict':model.state_dict(),\n",
        "                  'optimizer_state_dict':optimizer.state_dict(),\n",
        "                  'epoch': epoch},'./checkpoint')        \n",
        "\n"
      ],
      "metadata": {
        "id": "ymX7WfRKUJkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation Metric (UAR)"
      ],
      "metadata": {
        "id": "M0gVz-BtJlzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_auc_score\n",
        "\n",
        "def test(test_loader, model, epoch):\n",
        "    model.eval()\n",
        "    num_correct = 0\n",
        "\n",
        "\n",
        "    tp = 0\n",
        "    tn = 0\n",
        "    fp = 0\n",
        "    fn = 0\n",
        "\n",
        "\n",
        "    batch_bar = tqdm(total=len(test_loader), dynamic_ncols=True, position=0, leave=False, desc='Val', ncols=5)\n",
        "\n",
        "    y = []\n",
        "    y_hat = []\n",
        "\n",
        "    for i, (data, labels) in enumerate(test_loader):\n",
        "\n",
        "        data = data.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # apply transform and model on whole batch directly on device\n",
        "        # data = transform(data) # I don't think this step is necessary because the transformation already occurs in when pre-processing\n",
        "        outputs = model(data.squeeze(1))\n",
        "\n",
        "        predictions = torch.argmax(outputs, axis=1)\n",
        "\n",
        "        for label_i in range(len(labels)):\n",
        "            if (labels[label_i] == 1 and predictions[label_i] == 1):\n",
        "                tp += 1\n",
        "            elif (labels[label_i] == 1 and predictions[label_i] == 0):\n",
        "                fn += 1\n",
        "            elif (labels[label_i] == 0 and predictions[label_i] == 1):\n",
        "                fp += 1\n",
        "            elif (labels[label_i] == 0 and predictions[label_i] == 0):\n",
        "                tn += 1\n",
        "\n",
        "        num_correct += int((torch.argmax(outputs, axis=1) == labels).sum())\n",
        "\n",
        "        batch_bar.set_postfix(\n",
        "            acc=\"{:.04f}%\".format(100 * num_correct / (config['batch-size']*(i + 1))),\n",
        "            # fine_tuning_loss=\"{:.04f}\".format(float(total_fine_tuning_loss / (i + 1))),\n",
        "            num_correct=num_correct)\n",
        "\n",
        "        batch_bar.update()\n",
        "        \n",
        "        #wandb.log({\"train accuracy\": accuracy})\n",
        "\n",
        "        # # update progress bar\n",
        "        # pbar.update(pbar_update)\n",
        "\n",
        "        y.append(labels.cpu().numpy())\n",
        "        y_hat.append(predictions.cpu().numpy())\n",
        "    batch_bar.close()\n",
        "\n",
        "    sensitivity = tp / (tp + fn)\n",
        "    specificity = tn / (tn + tp)\n",
        "    uar = 0.5 * sensitivity + 0.5 * specificity\n",
        "\n",
        "    auroc = roc_auc_score(np.concatenate(y), np.concatenate(y_hat))\n",
        "    acc = 100 * num_correct / (config[\"batch-size\"] * (len(test_loader)))\n",
        "\n",
        "\n",
        "    # wandb.log({\"train accuracy\": accuracy})\n",
        "    #print(f\"Test Epoch: {epoch}\\tAccuracy: {acc}% UAR: {uar}\")\n",
        "    print(f\"Test Epoch: {epoch}\\tAccuracy: {acc}% UAR: {auroc}\")\n",
        "    print(\"Specificity: \", specificity)\n",
        "    print(\"Sensitivity: \", sensitivity)\n",
        "\n",
        "    # return uar, accuracy"
      ],
      "metadata": {
        "id": "JvCNlVt0yaPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(val_loader, model, 30)"
      ],
      "metadata": {
        "id": "Iz7oCqT54r4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation Function"
      ],
      "metadata": {
        "id": "7vGLvdRdNqHI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Here For Evaluation"
      ],
      "metadata": {
        "id": "uDxUpK-nJqG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate(model_res18, train_loader, val_loader)\n",
        "# evaluate(model_transformer, train_loader_audio, val_loader_audio)"
      ],
      "metadata": {
        "id": "C2pPyVovEuzr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}